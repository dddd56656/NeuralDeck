import 'dart:async';
import 'dart:io';
import 'dart:math';
import 'package:flutter/services.dart';
import 'package:path_provider/path_provider.dart';
import 'package:fllama/fllama.dart';
import 'brain_interface.dart';

class LLMBrain implements BrainInterface {
  bool _isInitialized = false;
  double? _contextId;

  // âœ… 1. ç¡®ä¿æ–‡ä»¶åä¸€è‡´
  static const String _modelFileName = 'tinyllama.gguf';

  @override
  Future<void> init() async {
    if (_isInitialized && _contextId != null) return;
    print("ğŸ§  (TinyLlama): Init...");

    try {
      final directory = await getApplicationDocumentsDirectory();
      final modelPath = '${directory.path}/$_modelFileName';
      final file = File(modelPath);

      // æ¬è¿æ¨¡å‹ (Assets -> App Doc Dir)
      if (!file.existsSync()) {
        print("ğŸ“¦ æ­£åœ¨é‡Šæ”¾ TinyLlama æ¨¡å‹ (600MB+)...");
        try {
          final ByteData data = await rootBundle.load(
            'assets/models/$_modelFileName',
          );
          final List<int> bytes = data.buffer.asUint8List();
          await file.writeAsBytes(bytes, flush: true);
          print("âœ… æ¨¡å‹é‡Šæ”¾å®Œæˆ");
        } catch (e) {
          throw Exception(
            "âŒ æ‰¾ä¸åˆ° assets/models/tinyllama.ggufï¼Œè¯·æ£€æŸ¥ pubspec.yaml: $e",
          );
        }
      }

      // åˆå§‹åŒ–å¼•æ“
      print("ğŸš€ Loading Engine...");
      final result = await Fllama.instance()!.initContext(
        modelPath,
        nCtx: 2048, // TinyLlama æ”¯æŒ 2048
        nThreads: 4, // 4çº¿ç¨‹
        nGpuLayers: 0, // å¼ºåˆ¶ CPU
        emitLoadProgress: true,
      );

      if (result != null && result.containsKey('contextId')) {
        _contextId = (result['contextId'] as num).toDouble();
        print("âœ… Engine Ready! ID: $_contextId");
        _isInitialized = true;
      } else {
        throw Exception("Init failed: $result");
      }
    } catch (e) {
      print("âŒ Init Error: $e");
      rethrow;
    }
  }

  // è¿™é‡Œçš„ analyzeTarget ä¿æŒä¸å˜...
  @override
  Future<Map<String, dynamic>> analyzeTarget(String inputTags) async {
    if (!_isInitialized) await init();
    final seed = inputTags.codeUnits.fold(0, (p, c) => p + c);
    final rnd = Random(seed);
    double r() => (rnd.nextInt(90) + 10) / 100.0;
    await Future.delayed(const Duration(milliseconds: 100));
    return {"ATK": r(), "DEF": r(), "SPD": r(), "MAG": r(), "LUCK": r()};
  }

  @override
  Stream<String> generateLoreStream(String inputTags) {
    // 1. åŸºç¡€æ£€æŸ¥
    if (!_isInitialized || _contextId == null) {
      print("âŒ å¤§è„‘æœªåˆå§‹åŒ–ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–...");
      // å¯ä»¥åœ¨è¿™é‡Œå°è¯•é‡æ–° init()ï¼Œæˆ–è€…ç›´æ¥æŠ¥é”™
      return Stream.error("Brain not initialized");
    }

    // ğŸ”´ [é‡ç‚¹ä¿®æ”¹] æŠ›å¼ƒæ‰€æœ‰å¤æ‚çš„ <|system|> æ ‡ç­¾
    // æ”¹ç”¨â€œå¼ºåˆ¶ç»­å†™â€æ¨¡å¼ã€‚
    // æ¯”å¦‚ï¼šInput="åˆ€", Prompt="è¿™æ˜¯ä¸€æŠŠèµ›åšæœ‹å…‹é£æ ¼çš„åˆ€ï¼Œå®ƒçš„ç‰¹ç‚¹æ˜¯"
    // æ¨¡å‹çœ‹åˆ°è¿™ä¸ªç»“å°¾ï¼Œä¸å¾—ä¸æŠŠåé¢çš„è¯è¡¥å…¨ã€‚
    final prompt =
        'Describe $inputTags in a Cyberpunk style. The $inputTags is';

    print("ğŸ“ å‘é€å¼ºåˆ¶ç»­å†™ Prompt: [$prompt] (Context ID: $_contextId)");

    final controller = StreamController<String>();

    // 2. ç›‘å¬æµ (ä¿æŒä¸å˜ï¼ŒåŠ äº†ç‚¹æ—¥å¿—)
    final sub = Fllama.instance()!.onTokenStream!.listen(
      (event) {
        // åªå¤„ç†å½“å‰ Context çš„æ¶ˆæ¯
        if (event['contextId'] == _contextId) {
          final token = event['token'] as String?;

          // ğŸ” è°ƒè¯•æ—¥å¿—ï¼šçœ‹çœ‹åˆ°åº•æœ‰æ²¡æœ‰å­—
          if (token != null && token.isNotEmpty) {
            print("ğŸ”¤ AIåå­—: [$token]");
            controller.add(token);
          } else {
            // æœ‰æ—¶å€™ç©ºåŒ…ä¹Ÿæ˜¯æ­£å¸¸çš„ï¼Œå¿½ç•¥å³å¯
          }

          // ç»“æŸåˆ¤æ–­
          if (event['is_end'] == true || event['done'] == true) {
            print("âœ… ç”Ÿæˆç»“æŸ (Done Signal)");
            controller.close();
          }
        }
      },
      onError: (e) {
        print("âŒ æµç›‘å¬æŠ¥é”™: $e");
        controller.addError(e);
      },
    );

    // 3. å‘é€è¯·æ±‚ (å‚æ•°å¾®è°ƒ)
    Fllama.instance()!
        .completion(
          _contextId!,
          prompt: prompt,
          nPredict: 50, // å¼ºåˆ¶å®šé•¿ 50 ä¸ª token
          temperature: 0.8, // æ¸©åº¦ç¨å¾®é«˜ç‚¹ï¼Œè®©å®ƒæ´»è·ƒç‚¹
          topK: 40, // æ ‡å‡†é‡‡æ ·å‚æ•°
          topP: 0.9, // æ ‡å‡†é‡‡æ ·å‚æ•°
          emitRealtimeCompletion: true, // å¿…é¡»å¼€å¯å®æ—¶æµ
        )
        .then((_) {
          print("ğŸ“¡ è¯·æ±‚å·²å‘é€ç»™åº•å±‚å¼•æ“");
        })
        .catchError((e) {
          print("âŒ è¯·æ±‚å‘é€å¤±è´¥: $e");
          controller.addError(e);
          controller.close();
        });

    // 4. æ¸…ç†é€»è¾‘
    controller.onCancel = () {
      print("ğŸ›‘ ç”¨æˆ·å–æ¶ˆäº†ç”Ÿæˆ");
      sub.cancel();
      // å¯é€‰ï¼šFllama.instance()!.stopCompletion(contextId: _contextId!);
    };

    return controller.stream;
  }

  @override
  Future<void> dispose() async {
    if (_contextId != null) {
      await Fllama.instance()!.releaseContext(_contextId!);
      _contextId = null;
    }
    _isInitialized = false;
  }
}
